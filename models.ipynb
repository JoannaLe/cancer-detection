{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoannaLe/cancer-detection/blob/master/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrXN61UMcsAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "GOOGLE_APPLICATION_CREDENTIALS = '/content/cancer-detection-fa915e095a9d.json'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5I2U41Hy5kX",
        "colab_type": "code",
        "outputId": "f2026df0-4269-4577-9578-8edef73ce50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# Open Google Cloud Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pjhYjpfJfTA",
        "colab_type": "code",
        "outputId": "e17722f4-71ee-4f57-cd7e-9812e0a16e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(os.getcwd())\n",
        "os.chdir(\"/content\")\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OMHE6yazCjF",
        "colab_type": "code",
        "outputId": "f83a081b-47d5-4d86-f6ba-6f8c35b0e1a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1032
        }
      },
      "source": [
        "# get X training data\n",
        "x_path = \"gdrive/My Drive/cancer-detection/patch-zoom-6\"\n",
        "print(os.listdir(x_path))\n",
        "X_train = []\n",
        "\n",
        "for patch_file in os.listdir(x_path):\n",
        "  patch_path = os.path.join(x_path, patch_file)\n",
        "  patch_arr = np.load(patch_path)\n",
        "  X_train.append(patch_arr)\n",
        "  \n",
        "print(type(X_train[0]))\n",
        "print(X_train[0])\n",
        "print(len(X_train))\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "# get Y training data\n",
        "y_path = \"gdrive/My Drive/cancer-detection/mask-zoom-6\"\n",
        "print(os.listdir(y_path))\n",
        "y_train = []\n",
        "\n",
        "for mask_file in os.listdir(y_path):\n",
        "  mask_path = os.path.join(y_path, mask_file)\n",
        "  mask = open(mask_path, 'r').read()\n",
        "  y_train.append(int(mask))\n",
        "  \n",
        "print(type(y_train[0]))\n",
        "print(y_train)\n",
        "print(len(y_train))\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['091-patch-0.npy', '091-patch-1.npy', '091-patch-2.npy', '091-patch-3.npy', '091-patch-4.npy', '091-patch-5.npy', '091-patch-6.npy', '091-patch-7.npy', '091-patch-8.npy', '091-patch-9.npy', '091-patch-10.npy', '091-patch-11.npy', '091-patch-12.npy', '091-patch-13.npy', '091-patch-14.npy', '091-patch-15.npy', '091-patch-16.npy', '091-patch-17.npy', '091-patch-18.npy', '091-patch-19.npy', '091-patch-20.npy', '091-patch-21.npy', '091-patch-22.npy', '091-patch-23.npy', '091-patch-24.npy', '091-patch-25.npy', '091-patch-26.npy', '091-patch-27.npy', '091-patch-28.npy', '091-patch-29.npy', '091-patch-30.npy', '091-patch-31.npy', '091-patch-32.npy', '091-patch-33.npy', '091-patch-44.npy', '091-patch-43.npy', '091-patch-34.npy', '091-patch-35.npy', '091-patch-45.npy', '091-patch-36.npy', '091-patch-39.npy', '091-patch-37.npy', '091-patch-47.npy', '091-patch-46.npy', '091-patch-38.npy', '091-patch-41.npy', '091-patch-48.npy', '091-patch-40.npy', '091-patch-49.npy', '091-patch-50.npy', '091-patch-42.npy', '091-patch-51.npy', '091-patch-52.npy', '091-patch-53.npy', '091-patch-54.npy', '091-patch-55.npy', '091-patch-56.npy', '091-patch-57.npy', '091-patch-58.npy', '091-patch-59.npy', '091-patch-60.npy', '091-patch-61.npy', '091-patch-62.npy', '091-patch-63.npy', '091-patch-64.npy', '091-patch-65.npy', '091-patch-66.npy', '091-patch-67.npy', '091-patch-68.npy', '091-patch-69.npy', '091-patch-70.npy', '091-patch-71.npy']\n",
            "<class 'numpy.ndarray'>\n",
            "[[[220 218 223]\n",
            "  [220 218 223]\n",
            "  [220 218 223]\n",
            "  ...\n",
            "  [219 217 222]\n",
            "  [219 217 222]\n",
            "  [219 217 222]]\n",
            "\n",
            " [[220 218 223]\n",
            "  [220 218 223]\n",
            "  [220 218 223]\n",
            "  ...\n",
            "  [219 217 222]\n",
            "  [219 217 222]\n",
            "  [219 217 222]]\n",
            "\n",
            " [[220 218 223]\n",
            "  [220 218 223]\n",
            "  [220 218 223]\n",
            "  ...\n",
            "  [219 217 222]\n",
            "  [219 217 222]\n",
            "  [219 217 222]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[221 219 224]\n",
            "  [221 219 224]\n",
            "  [221 219 224]\n",
            "  ...\n",
            "  [223 218 224]\n",
            "  [223 218 224]\n",
            "  [223 218 224]]\n",
            "\n",
            " [[221 219 224]\n",
            "  [221 219 224]\n",
            "  [221 219 224]\n",
            "  ...\n",
            "  [223 218 224]\n",
            "  [223 218 224]\n",
            "  [223 218 224]]\n",
            "\n",
            " [[221 219 224]\n",
            "  [221 219 224]\n",
            "  [221 219 224]\n",
            "  ...\n",
            "  [223 218 224]\n",
            "  [223 218 224]\n",
            "  [223 218 224]]]\n",
            "72\n",
            "['091-mask-0', '091-mask-1', '091-mask-2', '091-mask-3', '091-mask-4', '091-mask-5', '091-mask-6', '091-mask-7', '091-mask-8', '091-mask-9', '091-mask-13', '091-mask-10', '091-mask-14', '091-mask-11', '091-mask-15', '091-mask-12', '091-mask-16', '091-mask-17', '091-mask-18', '091-mask-19', '091-mask-20', '091-mask-21', '091-mask-22', '091-mask-23', '091-mask-24', '091-mask-25', '091-mask-26', '091-mask-27', '091-mask-28', '091-mask-29', '091-mask-30', '091-mask-31', '091-mask-32', '091-mask-42', '091-mask-33', '091-mask-43', '091-mask-44', '091-mask-34', '091-mask-45', '091-mask-35', '091-mask-46', '091-mask-36', '091-mask-47', '091-mask-37', '091-mask-49', '091-mask-48', '091-mask-40', '091-mask-38', '091-mask-50', '091-mask-41', '091-mask-39', '091-mask-51', '091-mask-53', '091-mask-52', '091-mask-54', '091-mask-55', '091-mask-56', '091-mask-57', '091-mask-59', '091-mask-58', '091-mask-60', '091-mask-61', '091-mask-62', '091-mask-63', '091-mask-64', '091-mask-65', '091-mask-66', '091-mask-67', '091-mask-68', '091-mask-69', '091-mask-71', '091-mask-70']\n",
            "<class 'int'>\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmPAle2Bed6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test 1 model at zoom level 6\n",
        "img_shape = (224,224,3)\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "model1 = ResNet50(include_top=True, weights='imagenet', input_shape=img_shape)\n",
        "model1.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oqvtvP0gy48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2y95JhPiD54",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "e5b7db82-adaf-4be5-c7d0-7f943a17760d"
      },
      "source": [
        "img_shape = (224,224,3)\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), activation='relu', input_shape=img_shape))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 222, 222, 64)      1792      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3154176)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                201867328 \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 201,869,185\n",
            "Trainable params: 201,869,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vSSA6ogkZRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "e0263320-9b75-4f2f-b734-d3e034dcfaf2"
      },
      "source": [
        "print(X_train.shape)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72, 224, 224, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "72/72 [==============================] - 12s 170ms/step - loss: 3.9834 - acc: 0.6528\n",
            "Epoch 2/10\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.4477 - acc: 0.9722\n",
            "Epoch 3/10\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.4477 - acc: 0.9722\n",
            "Epoch 4/10\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.4477 - acc: 0.9722\n",
            "Epoch 5/10\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.4477 - acc: 0.9722\n",
            "Epoch 6/10\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.4477 - acc: 0.9722\n",
            "Epoch 7/10\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.4477 - acc: 0.9722\n",
            "Epoch 8/10\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.4477 - acc: 0.9722\n",
            "Epoch 9/10\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.4477 - acc: 0.9722\n",
            "Epoch 10/10\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.4477 - acc: 0.9722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4c23562e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Uam62vnV0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5gawGnyc4_p",
        "colab_type": "text"
      },
      "source": [
        "## Model 1\n",
        "4 resnet models with a concatenation layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFElnwjBc9Px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = (300,300,3)\n",
        "\n",
        "model1 = ResNet50(include_top=True, weights='imagenet', input_shape=img_shape)\n",
        "model2 = ResNet50(include_top=True, weights='imagenet', input_shape=img_shape)\n",
        "model3 = ResNet50(include_top=True, weights='imagenet', input_shape=img_shape)\n",
        "model4 = ResNet50(include_top=True, weights='imagenet', input_shape=img_shape)\n",
        "\n",
        "# concatenation layer\n",
        "concat = Average()([model1.output, model2.output, model3.output, model4.output])\n",
        "\n",
        "full_model = Model([model1.input, model2.input, model3.input, model4.input], concat)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLa3EyLAwPMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to train, call\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "full_model.fit([X_train1, X_train2, X_train3, X_train4],\n",
        "               [Y_train1, Y_train2, Y_train3, Y_train4],\n",
        "                epochs=EPOCHS,\n",
        "                batch_size=BATCH_SIZE)\n",
        "\n",
        "score = model.evaluate([X_test1, X_test2, X_test3, X_test4],\n",
        "                       [Y_test1, Y_test2, Y_test3, Y_test4],\n",
        "                       batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb4jecpVApes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT3fVjtic9e-",
        "colab_type": "text"
      },
      "source": [
        "# Model 2\n",
        "Transfer Learning using weights from Resnet \\\\\n",
        "Extract features from Resnet weights and training/test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9pcLg6adOND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_shape = (300,300,3)\n",
        "\n",
        "base = ResNet50(include_top=True, weights='imagenet', input_shape=img_shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}